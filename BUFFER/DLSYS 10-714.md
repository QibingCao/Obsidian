---

类型: 笔记
创建日期: 2024-07-29
修改日期: 2024-07-29
---
# linear hopothesis
## supervised learning
对于类似手写数字分类的任务，对于机器来说无法像人类一样很直观的看到图像，人类无法很严谨地给出数字图像的定义。
但是我们能很容易的用图片和已经做好的标签去训练一个系统，让他的识别正确率尽可能的高
![[Pasted image 20240729151752.png]]

我们想让模型输出分类的结果，相比于直接对为一错为零这种无法优化的loss（小范围的输出变化不会影响结果，模型不找不到减少loss的方向），让模型输出为某个类的概率，以便优化。
### softmax
又因为输出的结果是实数，为了让输出满足概率的性质（0到1之间，概率总和为1）于是给每个维度的输出都套一层e指数，并除以总和。

![[Pasted image 20240729160036.png]]

![[Pasted image 20240729193241.png]]针对于所有的监督学习来说，我们要最小化所有的loss，此处为softmax loss。
![[Pasted image 20240729194512.png]]
最小化的过程相当于求参数矩阵θ的梯度，此时将loss函数看作是θ的函数f(θ)。
此时根据已有的输出结果，求出θ的梯度，梯度的每一项都是偏导，**即固定其他维度的参数不变，求此处位置的导数**。
倒三角下面的θ指的是对θ求导。
梯度代表了在当前位置函数向值最增大的方向，想要最小化那就要向梯度的相反方向。
![[Pasted image 20240729194450.png]]
理论上做法应该是，对于训练集上的所有输入样本，分别求出每个样本对应的梯度，然后**累加**得到全局的梯度（loss本来就是累加得出的平均数），再用全局梯度更新θ。
但是在实际使用中并不是这样做的。完整的计算全部样本的梯度对于大量数据来说是不现实的。实际上是用一小部分的数据求出梯度然后更新θ，这样就是大量的θ数据更新而不是大量梯度计算。

小批量替代整体的前提是无偏估计和独立同分布。本来数据集就是对某一个物理规律的数据采样，他也不是整个物理规律应用的全部数据来源。所以数据集就是符合无偏估计和独立同分布的。
可以把小批量理解为整个数据集的带噪声的采样。
![[Pasted image 20240729202208.png]]
### 随机梯度下降（Stochastic Gradient Descent, SGD）
随机梯度下降通过在每次迭代中只使用一个或一小部分样本来近似地计算梯度，从而进行参数更新。
#### 步骤：
1. **初始化**：随机初始化模型参数。
2. **随机选择样本**：从训练数据集中随机选择一个样本 xix_ixi​ 及其对应的标签 yiy_iyi​。
3. **计算梯度**：计算选定样本上的损失函数的梯度。
4. **更新参数**：根据计算出的梯度更新参数。 θ:=θ−η∇θJ(θ;xi,yi)\theta := \theta - \eta \nabla_\theta J(\theta; x_i, y_i)θ:=θ−η∇θ​J(θ;xi​,yi​)
#### 特点：
- **单样本更新**：每次迭代只使用一个样本，更新频繁。
- **计算效率高**：每次更新计算成本低，适合大型数据集。
- **噪声大**：由于使用单样本进行更新，每次更新方向可能会偏离全局最优方向，导致收敛过程中的抖动。
- **更快收敛**：虽然每次更新带有噪声，但在大多数情况下，SGD能比GD更快到达最优点，尤其是在非凸优化问题中。

### 梯度计算（注意所有梯度都是针对loss->标量，因此梯度维度和原矩阵维度相同，参考limu）
loss对输出结果的导数
这个后面要用
![[Pasted image 20240729204458.png]]
导数就是输出结果减去真实值
![[Pasted image 20240729204447.png]]
#### 对θ求导
真实在做的：假设所有参数都是标量，采用经典的链式法则求出结果并相加。这种方法在实际应用中更常用，但需要数值验证来确保其正确性。
![[Pasted image 20240729205449.png]]
直接当做标量用链式法则，前半段就是前面过的对h偏导，后面就是x本身。注意维度不同，我们要的梯度维度应该等同于θ的维度n，k，所以直接给上述结果换换位置相乘，难绷
![[Pasted image 20240729211359.png]]

发现梯度是真滴好求，结果都是算好的，直接乘起来就完事了
![[Pasted image 20240729212348.png]]
#### 插曲
在看softmax对h求导时，发现长得巨像sigmoid，接着又发现sigmoid和softmax本来就是一个东西，softmax当类别只有两个时，就是sigmoid

# neural network
对于无法使用线性假设来分类的问题
一个思路是可以说明，任意维度的线性变换基本上是等价的。在原本的线性变换基础上增加新的线性矩阵对结果不起作用。
因此我们可以在线性变换之后，在添加非线性的变换。

为什么两层的神经网络理论上就可以拟合任意闭区间内的smooth函数，而我们要用所谓的deep的多层设计呢？
![[Pasted image 20240730103537.png]]
以ReLU为例，我们可以使用ReLU一段一段的拼出原本的函数，当函数上的采样点足够密集，拟合的函数误差就足够小。
![[Pasted image 20240730103649.png]]

回到问题
![[Pasted image 20240730104016.png]]
#### 理由一：它们像大脑一样工作（They work like the brain!）
- **解释**：有人认为深度网络的工作方式类似于人脑的神经网络。
- **评论**：实际上，深度网络并不像大脑那样工作。虽然受神经科学的启发，但它们的工作原理和大脑的生物机制有很大不同。
- **结论**：否定这种观点，深度网络并不是真正像大脑那样工作。
#### 理由二：深度电路在理论上更高效（Deep circuits are provably more efficient!）
- **解释**：在理论上，深度电路（深度网络）在表示某些函数时比浅层网络更高效。
- **评论**：虽然深度网络在理论上可以更高效地表示某些函数，但这些函数可能是神经网络实际无法学习的，比如奇偶性（parity）问题。
- **结论**：肯定这种观点，但指出这种理论高效性在实际应用中可能有限。
#### 理由三：经验上它们在固定参数数量时表现更好（Empirically it seems like they work better for a fixed parameter count!）
- **解释**：在实际应用中，对于相同数量的参数，深度网络通常表现得更好。
- **评论**：这是基于经验的观察，虽然没有深入解释为什么，但这种现象确实存在。
- **结论**：肯定这种观点，指出在实际应用中深度网络确实表现得更好。

### 三个部分解释
对于任何一个模型，都可以分为三个部分：
hypothesis class，参数模型
loss function，损失函数
optimization procedure，优化器
在举例的NN种中，我们的损失函数和优化器和之前没有任何区别，因为我们的任务依旧是多分类。
![[Pasted image 20240730104858.png]]


## 反向传播推导
多层网络的数学表示，**注意下标**
![[Pasted image 20240730111239.png]]

对于一个两层神经网络，W2是后一层，W1是前一层。我们用标量的链式法则先取巧地将梯度转化为**容易计算的表示**，然后再根据容易计算表示的**维度**，**来最终确认梯度结果是怎么乘起来的**。

先计算w2
![[C51415AA086B8745F25D509BF4D0E0FD.png]]

再计算w1，w1要链式法则多几次。w1梯度的n1只有X能够提供，那么X必然在最左边，然后消除掉n3，得到最终的结果。
![[D21833F913DE599CCFEED32651C2BF87.png]]

**记住，必须要数值测试你的结果是否正确**，因为这么推导很不严谨。

结果对Wi的梯度就等于结果对Zi输出层的梯度乘输出层对Wi的梯度（本来就是按照标量推导的）
![[F073787A6039F8D824B5E1AD285DAC7C.png]]![[Pasted image 20240730122912.png]]
![[8305C0CA1DD5B2458222035ED8226618.png]]
G L+1 就是输出的梯度，就等于S-Iy（在softmax/cross entropy中），然后反向计算就完事了
![[Pasted image 20240730131715.png]]
从公式可以看出，反向传播时需要前向计算得到的中间结果的值，所以在前项计算时我们不能简单的计算完就丢弃他，而是保存起来以备反向传播使用。
这就是计算梯度的tradeoff，你想要速度快就得保存中间值。
这就会导致大量的内存占用，像最新的Llama3参数量达到405B，恐怖的数字。。

我们在这个式子中抽取出迭代关系（注意下图中的·都是简化表达，不是真实计算）
![[Pasted image 20240730133400.png]]
![[Pasted image 20240730133234.png]]